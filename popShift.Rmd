---
title: "Assessing author population shifts following introduction of journal open data policies"
author: "Tom Hardwicke"
date: "2/4/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
#library(viridis)
library(knitr)
#library(papaja)
btstrp.N <- 999 # number of bootstrap samples
```

# Background

We have run two observational studys in which we found large increases in data availability following the introduction of open data policys at two journals: Psychological Science, and Cognition. However, one possibility is that the results are affected by self-selection bias: it could be that the policy attracted authors to the journal who were already inclined towards sharing data, and deterred authors who were not. In order to investigate this possibilitity, we are conducted additional analyses of author retention at these journals before and after the policy was introduced.

Here we define author retention as the overlap (using Dice coefficient) in authors publishing at the journal in a given year relative to the previous three years (note the choice of three is relatively arbitrary - it just seems like it might provide a more stable estimate of author retention). If there is a general population shift caused by the policy intervention, we might expect to see a marked reduction in the author retention index shortly after the policy was introduced.

# Questions

1. We are interested in hearing thoughts on whether the proposed method of calculating the Dice coefficient etc is a reasonable way to address this problem.

2. A more specific problem we have is how to calculate confidence intervals for the Dice coefficient. We have attempted a bootstrapping approach, but the mean Dice for the bootstrap samples (and thus the bootstraped CIs) is consistently lower than the actual Dice. The specific code we are using is included below.


# Analysis

## Functions

First we specify some functions to use in the analysis.

Function to calculate dice coefficient: (NB - sometimes authors appear more than once in each year. We select only unique elements. Not sure if this is correct.)

```{r}
dice <- function(vector1, vector2){
  v1 <- unique(vector1) # select only unique elements
  v2 <- unique(vector2) # select only unique elements
  
  overlap <- intersect(v1, v2) # find elements that are present in both vectors
  overlapN <- length(overlap) # find number of overlapping elements
  
  v1N <- length(v1) # get length of vector 1
  v2N <- length(v2) # get length of vector 2
  
  diceCoeff <- (2*overlapN) / (v2N + v1N) # calculate dice coefficient
  
  return(diceCoeff)
}
```

Function to generate samples with replacement and calculate dice each time:

```{r}
bootDice <- function(v1, v2) {
  v1_new <- sample(v1, size = length(v1), replace = T)
  v2_new <- sample(v2, size = length(v2), replace = T)
  return(dice(v1_new, v2_new))
}
```

Wrapper function uses dice() and bootDice() to calculate Dice coefficent between authors publishing target year and previous 3 years (the "Author Retention Index"):

```{r}
rollingDice <- function(targetYear){
  
  previousYears <- as.character(c(targetYear-1, targetYear-2, targetYear-3)) # get list of previous 3 years
  targetYear <- as.character(targetYear) # target year as character
  
  targetAuthors <- d %>% filter(year == targetYear) %>% pull(author) # select authors in target year
  previousAuthors <- d %>% filter(year %in% previousYears) %>% pull(author) # select authors in previous three years
  
  diceOut <- dice(targetAuthors, previousAuthors) # get dice coefficient

  myDice <- replicate(btstrp.N, bootDice(targetAuthors, previousAuthors)) # bootstrap
  diceCI <- quantile(myDice, c(.025, .975)) # calculate confidence intervals
  
  outputDF <- data.frame(targetYear = as.numeric(targetYear), dice = diceOut, lwr.ci = diceCI[1], upr.ci = diceCI[2], btstrp.dice.mean = mean((myDice)), row.names = NULL) # combine Dice, CIs, and the mean dice for bootstrapped samples
  
  return(outputDF)
}
```


## Run analysis for the journal Psychological Science

```{r}
d <- read_csv("AuthorList_PsychSci.csv")
```

Apply the functions:

```{r}
yearDice <- data.frame(targetYear = seq(2011,2017, 0001)) %>%
  rowwise() %>%
  do(rollingDice(.$targetYear))

kable(yearDice)
```

As you can see, the mean Dice for the bootstrap samples is consistently lower than the actual Dice.

Plot Dice across the time series:

```{r}
ggplot(data = yearDice) +
  geom_line(aes(x = targetYear, y = dice, group = 1), colour = "indianred1", size = 1.1) +
  geom_vline(xintercept=2014.05) +
  scale_x_continuous(breaks = seq(2011, 2017, 0001), labels = seq(2011, 2017, 0001)) +
  ylim(0,0.2) +
  ylab("Author retention index") +
  xlab("Publication year") +
  ggtitle("Psychological Science")
  #theme_apa()
```

Author rentention index appears fairly stable both before and after introducion of the policy - there is perhaps a small decline. No evidence of a large population shift.

## Run analysis for the journal Cognition

Note we have data going back further here so the date range is larger.

```{r, include=FALSE}
d <- read_csv("AuthorList_Cognition.csv")
```

Apply the functions for Cognition:

```{r}
yearDice <- data.frame(targetYear = seq(2008,2017, 0001)) %>%
  rowwise() %>%
  do(rollingDice(.$targetYear))

kable(yearDice)
```

Same problem - mean Dice and CIs from bootstrap samples are consistently lower than actual Dice.

```{r}
ggplot(data = yearDice) +
  geom_line(aes(x = targetYear, y = dice, group = 1), colour = "indianred1", size = 1.1) +
  geom_vline(xintercept=2015.12) +
  scale_x_continuous(breaks = seq(2008, 2017, 0001), labels = seq(2008, 2017, 0001)) +
  ylim(0,0.2) +
  ylab("Author overlap with previous three years (Dice coeffcient)") +
  xlab("Publication year") +
  ggtitle("Cognition")
  #papaja::theme_apa()
```

Author rentention index appears stable both before and after introducion of the policy - no evidence of a population shift.